---
layout: post
title: Change or Continuity?
subtitle: Topic Modeling of Thailand in Transition
gh-repo: naponjatusripitak/polisci490/Project
gh-badge: [star, fork, follow]
tags: [LDA, politics]
---

## Introduction
![alt text](https://naponjatusripitak.github.io/polisci490/Project/thenation.png)

Do newspaper articles that are published before and after the occurrence of a regime transition differ systematically in terms of their topic coverage and content? Utilizing an original dataset containing all political news published from 2013 to 2015 by _The Nation_, an English-language daily newspaper in Thailand, this project explores the relationship between regime transition and the media. Specifically, I analyze Thai newspaper articles that were published under democratic rule (pre-May 2014 coup) and those that were published under military rule (post-May 2014 coup), using latent Dirichlet allocation (LDA) to examine topic variation amidst a regime transition. Then, leveraging the topics generated by the model, I conduct a series of quantitative content analyses for assessing the frequencies of words and measuring the sentiments associated with a given topic over time.

## Data Collection and Pre-Processing
All newspaper articles published by The Nation from 2013 to 2015 were collected from the Nexis Uni database via Rselenium, which extracted relevant information such as the headline, content, and date. The search query used in this process of data collection is _thailand_. For the analysis, only articles that contain a set of keywords that are predictive of their political content were retained for the analysis. These keywords include: politic*, gov*, democ*, Yingluck, junta, Prayut, Pheu, and NCPO. One problem with this strategy is that the keyword selection process is potentially arbitrary, inadequate for minimizing false positives and lacking in terms of intercoder reliability. An alternative strategy would be to use a computer-assisted approach offered by King, Lam and Roberts (2017), relying on an unsupervised selection of documents in search set, _S_, into target set, _T_, based on a hand-coded reference set _R_. However, in this project, the dictionary-based approach is selected for computational efficiency. This process yields a total of 20,703 articles where the average length is 580 words.
