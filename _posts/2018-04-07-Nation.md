---
layout: post
title: Change or Continuity?
subtitle: Topic Modeling of Thailand in Transition
gh-repo: naponjatusripitak/polisci490/Project
gh-badge: [star, fork, follow]
tags: [LDA, politics]
---
## Introduction
<p align="center">
<img src="https://naponjatusripitak.github.io/polisci490/Project/thenation.png">
</p>

Do newspaper articles that are published before and after the occurrence of a regime transition differ systematically in terms of their topic coverage and content? Utilizing an original dataset containing all political news published from 2013 to 2015 by _The Nation_, an English-language daily newspaper in Thailand, this project explores the relationship between regime transition and the media. Specifically, I analyze Thai newspaper articles that were published under democratic rule (pre-May 2014 coup) and those that were published under military rule (post-May 2014 coup), using latent Dirichlet allocation (LDA) to examine topic variation amidst a regime transition. Then, leveraging the topics generated by the model, I conduct a series of quantitative content analyses for assessing the frequencies of words and measuring the sentiments associated with a given topic over time.

## Data Collection and Pre-Processing
All newspaper articles published by The Nation from 2013 to 2015 were collected from the Nexis Uni database via Rselenium, which extracted relevant information such as the headline, content, and date. The search query used in this process of data collection is _thailand_. For the analysis, only articles that contain a set of keywords that are predictive of their political content were retained for the analysis. These keywords include: politic*, gov*, democ*, Yingluck, junta, Prayut, Pheu, and NCPO. One problem with this strategy is that the keyword selection process is potentially arbitrary, inadequate for minimizing false positives and lacking in terms of intercoder reliability. An alternative strategy would be to use a computer-assisted approach offered by King, Lam and Roberts (2017), relying on an unsupervised selection of documents in search set, _S_, into target set, _T_, based on a hand-coded reference set _R_. However, in this project, the dictionary-based approach is selected for computational efficiency. This process yields a total of 20,703 articles where the average length is 580 words.

### Data Collection
```R
# Set working directory
setwd("~/polisci490/Project")

# Load packages
packages <- c("xml2","rvest", "dplyr", "tm", "tidytext", "ggplot2", "SnowballC", "tidyverse", "lubridate", "stringr", "httr", "SnowballC", "wdman", "RSelenium", "tcltk", "XML", "topicmodels", "stringi", "LDAvis", "slam", "ldatuning", "kableExtra", "widyr", "igraph", "ggraph", "fmsb", "pander")

load.packages <- function(x) {
  if (!require(x, character.only = TRUE)) {
    install.packages(x, dependencies = TRUE)
    library(x, character.only = TRUE)
  }
}

lapply(packages, load.packages)

########## Data Collection (Don't Run this!!)########## 

# Run Selenium Server
rD <- rsDriver()
remDr <- remoteDriver(remoteServerAddr = "localhost" 
                      , port = 4567L
                      , browserName = "chrome"
)


# Log in
remDr$open()
remDr$navigate("https://advance-lexis-com.turing.library.northwestern.edu/api/permalink/920dc8d1-6625-47c3-bdd4-b1c073f28f78/?context=1516831")
username <- remDr$findElement(using = 'id', value = "IDToken1")
password <- remDr$findElement(using = 'id', value = "IDToken2")
username$sendKeysToElement(list("id"))
password$sendKeysToElement(list("pass", "\uE007"))

# click

continue <- remDr$findElement(using = "xpath", "//*[@id='33Lk']/div/div/div/section/div/menu/input[1]")
continue$clickElement()

# Initializing an empy dataframe
# df <- data.frame(title=NULL, text=NULL, date=NULL, length=NULL)

# Scraping

remDr$setTimeout(type = "page load", milliseconds = 100000)
remDr$setImplicitWaitTimeout(milliseconds = 100000)
for(i in 1:20000){
  tryCatch({
    title <- remDr$findElement(using = "id", "SS_DocumentTitle")
    date <- remDr$findElement(using = "xpath", "//*[@id='document']/section/header/p[3]")
    length <- remDr$findElement(using = "xpath", "//*[@id='document']/section/span/div[2]")
    body <- remDr$findElement(using = "xpath", "//*[@id='document']/section/span")
    
    preptext <- function(x){ data.frame(matrix(unlist(x), nrow=length(x), byrow=T))}
    
    title_txt <- preptext(title$getElementText())
    date_txt <- preptext(date$getElementText())
    length_txt <- preptext(length$getElementText())
    body_txt <- preptext(body$getElementText())
    
    docdf <- data.frame(title=title_txt, text=body_txt, date=date_txt, length=length_txt)
    df <- rbind(df, docdf)
    
    Sys.sleep(sample(1:4, 1))
    next_page <- remDr$findElement(using="xpath", "//*[@id='_gLdk']/div/form/div[1]/div/div[14]/nav/span/button[2]")
    next_page$highlightElement()
    next_page$clickElement()
    
  }, error=function(e){
    Sys.sleep(sample(1:10, 1))
    title <- remDr$findElement(using = "id", "SS_DocumentTitle")
    date <- remDr$findElement(using = "xpath", "//*[@id='document']/section/header/p[3]")
    length <- remDr$findElement(using = "xpath", "//*[@id='document']/section/span/div[2]")
    body <- remDr$findElement(using = "xpath", "//*[@id='document']/section/span")
    
    preptext <- function(x){ data.frame(matrix(unlist(x), nrow=length(x), byrow=T))}
    
    title_txt <- preptext(title$getElementText())
    date_txt <- preptext(date$getElementText())
    length_txt <- preptext(length$getElementText())
    body_txt <- preptext(body$getElementText())
    
    docdf <- data.frame(title=title_txt, text=body_txt, date=date_txt, length=length_txt)
    df <- rbind(df, docdf)
    
    Sys.sleep(sample(1:4, 1))
    next_page <- remDr$findElement(using="xpath", "//*[@id='_gLdk']/div/form/div[1]/div/div[14]/nav/span/button[2]")
    next_page$highlightElement()
    next_page$clickElement()
  })}
```

### Data Pre-processing
```R
# Assign variable names
names(df) <- c("title", "text", "date", "wordcount")

# Set date
df$date <- mdy(as.character(df$date))

# Clean content
df$text <- gsub("^.*Body\n|Classification.*$","", as.character(df$text))
df$text <- gsub( " *@.*?; *", "", as.character(df$text))
df$text <- gsub( "*â€", "", as.character(df$text))
df$text <- gsub( "*â€“", "", as.character(df$text))
df$title <- gsub( " *@.*?; *", "", as.character(df$title))
df$title <- gsub( "*â€", "", as.character(df$title))
df$title <- gsub( "*â€“", "", as.character(df$title))
df$title <- gsub( "*#124", "", as.character(df$title))
df$text <- gsub( "*#124", "", as.character(df$text))
df$text <- gsub("*Prayuth", "Prayut", as.character(df$text)) # Prayut & Prayuth
df$title <- gsub("*Prayuth", "Prayut", as.character(df$title)) # Prayut & Prayuth

# Get word count
df$wordcount <- as.numeric(gsub("Length: | words", "", df$wordcount))

# Filter for politics
keyword <- c("politic*", "gov*", "democ*", "Yingluck", "junta", "Prayut", "Pheu", "NCPO")
pattern <- grepl(paste(keyword, collapse = "|"), df$text)
df <- df[pattern, ]

# select date Jan 2013 - Sep 2015
df.2013 <- filter(df, date >= "2013-01-01" & date < "2016-01-01")

# Remove duplicate rows
df.2013 <- distinct(df.2013)

# Add doc_id
df.2013 <- df.2013 %>% mutate(doc_id = seq.int(nrow(df.2013)))

# Finalize dataset
df.2013 <- df.2013 %>% select(doc_id, text, everything())
```
<p align="center">
<img src="https://naponjatusripitak.github.io/polisci490/Project/datastructurenation.png">
</p>
<p align="center">Table 1: Data Structure</p>

Using the tm package, I converted the data to a corpus object, transformed words to lower cases and removed stop words, numbers, punctuations, followed by stemming and removing white spaces. Then, I parsed the corpus to a document-term matrix with articles as documents in the rows and terms in the columns. Finally, sparse terms that appear in less than 0.01 of all documents are removed. One consideration that must taken into account is that the topic models may be sensitive to these pre-processing choices (Denny and Sperling 2017). In theory, transforming to lower cases, removing numbers and removing punctuations should not significantly alter the findings of this project, whereas stemming and removing stop words may result in a loss of information or generate noise in the model. Although a comparison of findings with different preprocessing choices is not presented here, this can be implemented in future work to test the robustness of the topic models.  

```R
# Create corpus
nation <- VCorpus(DataframeSource(df.2013))

# Pre-process + generate document-term matrix
nation.dtm <- nation %>% 
  tm_map(content_transformer(tolower)) %>%
  tm_map(removeWords, stopwords("english")) %>%
  tm_map(removeNumbers) %>%
  tm_map(removePunctuation) %>%
  tm_map(stemDocument) %>%
  tm_map(stripWhitespace) %>%
  DocumentTermMatrix() %>%
  removeSparseTerms(sparse = 0.99)
```

## Choosing the Number of Topics
Following Blei, Ng and Jordan (2003), I employ latent Dirichlet allocation (LDA) as an unsupervised method for learning the topics associated with the newspaper articles. This allows for documents to be represented as mixtures of topics characterized by a probabilistic distribution of words, in contrast to other models that treat documents as discrete and limited to a single topic.

I also considered using structural topic modeling (STM) as an alternative. However, given the lack of available covariates on which to condition the topic model on, LDA is chosen for the study. One consequence of this is that the model is likely to be noisy given that informative metadata such as news category is not included as part of the modeling.
                                 
To find the optimal number of topics for fitting LDA models, I use _ldatuning_, an R package that estimates the performance of LDA models based on four different metrics. According to these metrics, the performance of LDA models improves most significantly when moving to 40 and 60 topics.

```R
result <- FindTopicsNumber(
  nation.dtm,
  topics = seq(from = 20, to = 200, by = 10),
  metrics = c("Griffiths2004", "CaoJuan2009", "Arun2010", "Deveaud2014"),
  method = "Gibbs",
  control = list(seed = 77),
  mc.cores = 2L,
  verbose = TRUE
)
FindTopicsNumber_plot(result)
```
<p align="center">
<img src="https://naponjatusripitak.github.io/polisci490/Project/ldatuning.png">
</p>
<p align="center">Figure 1: LDA Tuning</p>

## Topic Model (2013-2015)
 I implemented four topic models with k = 20, 30, 40 and 60. Out of all four models, the model with k = 60 is most informative in terms of providing topic labels that are helpful for making an informed guess as to what each topic is about. Each document is modeled as a mixture of topics and, under the bag-of-words assumption, a distribution of words with probabilities of being associated with various topics. Table 2 provides all sixty topics and the terms most frequently associated with them. Figure 2 illustrates an interactive web-based visualization of the model.

```R
### LDA
mod.out.60 <- LDA(nation.dtm, k=60, control = list(seed=6))
class(mod.out.60) <- "LDA"
tidy(mod.out.60)

### Generate topic labels (top 30 terms)
nation.topics <- topics(mod.out.60, 1)
nation.terms <- as.data.frame(terms(mod.out.60, 30), stringsAsFactors = FALSE)

### Table
topic_list <- data.frame(t(nation.terms))
topic_list <- within(topic_list, x <- paste(X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X12, X13, X14, X15, X16, X17, X18, X19, X20, sep=", ")) %>% select(x)
colnames(topic_list) <- NULL
topic_list <- tibble::rownames_to_column(topic_list)
colnames(topic_list) <- c("Topic", "Keys")
```
| Topic | Keys |
|--------|--------|
|Topic 1  |health, hospit, medic, patient, treatment, doctor, diseas, drug, healthcar, peopl, also, medicin, cancer, can, servic         |
|Topic 2  |rice, farmer, price, tonn, govern, scheme, agricultur, million, export, rubber, said, farm, market, pledg, crop               |
|Topic 3  |channel, digit, broadcast, licenc, nbtc, servic, oper, auction, telecom, nation, advertis, station, content, telecommun, true |
|Topic 4  |myanmar, lao, countri, cambodia, border, yangon, vietnam, mekong, neighbour, foreign, open, local, group, develop, year       |
|Topic 5  |asean, region, econom, countri, cooper, aec, thailand, communiti, member, trade, also, develop, will, integr, agreement       |
|Topic 6  |provinc, chiang, water, mai, district, flood, local, river, dam, nakhon, buri, area, rai, mae, thani                          |
|Topic 7  |will, year, new, next, thailand, also, expect, countri, thai, futur, take, come, hope, can, first                             |
|Topic 8  |asia, region, southeast, asian, countri, world, global, vietnam, east, asiapacif, thailand, india, across, singapor, pacif    |
|Topic 9  |polit, thailand, countri, thai, state, militari, nation, democraci, govern, intern, year, right, power, conflict, peopl       |
|Topic 10 |media, social, facebook, post, news, onlin, peopl, thai, page, report, messag, websit, inform, also, video                    |
|Topic 11 |meet, said, will, yesterday, month, thailand, day, week, report, two, last, announc, offici, schedul, committe                |
|Topic 12 |per, cent, year, quarter, growth, increas, expect, month, price, last, averag, rate, first, forecast, drop                    |
|Topic 13 |malaysia, singapor, indonesia, fish, philippin, boat, malaysian, indonesian, sea, ship, vessel, said, jakarta, marin, countri |
|Topic 14 |trade, thai, thailand, export, industri, product, invest, countri, said, import, busi, manufactur, year, will, market         |
|Topic 15 |attack, secur, bomb, kill, incid, death, polic, peopl, fire, accid, violenc, bangkok, injur, also, victim                     |
|Topic 16 |busi, custom, servic, compani, thailand, provid, new, manag, market, oper, growth, store, retail, cloud, industri             |
|Topic 17 |mobil, use, technolog, internet, servic, devic, onlin, user, phone, data, card, can, app, applic, smart                       |
|Topic 18 |peac, muslim, group, south, talk, thai, insurg, govern, islam, secur, leader, region, offici, deep, local                     |
|Topic 19 |say, like, one, just, time, want, get, peopl, can, work, think, now, make, year, know                                         |
|Topic 20 |ministri, said, govern, minist, plan, nation, state, committe, budget, will, polici, financ, propos, offic, privat            |
|Topic 21 |economi, econom, growth, rate, thailand, invest, year, polici, domest, global, export, govern, bank, polit, market            |
|Topic 22 |polic, said, arrest, suspect, rohingya, yesterday, investig, thailand, report, two, nation, thai, alleg, found, offici        |
|Topic 23 |china, chines, south, hong, korea, kong, india, beij, korean, taiwan, japan, indian, thailand, mainland, includ               |
|Topic 24 |court, right, case, law, legal, nation, rule, public, also, issu, violat, human, alleg, justic, report                        |
|Topic 25 |team, player, thai, footbal, club, game, match, cup, play, nation, coach, fan, leagu, world, thailand                         |
|Topic 26 |film, music, perform, festiv, show, thai, danc, movi, theatr, year, stage, also, audienc, play, song                          |
|Topic 27 |hotel, offer, call, wine, bangkok, room, resort, night, includ, beach, two, book, spa, restaur, ticket                        |
|Topic 28 |tour, said, play, win, golf, round, last, shot, hole, year, open, two, birdi, week, first                                     |
|Topic 29 |japan, japanes, tokyo, thailand, thai, yen, visit, also, oversea, bangkok, open, first, year, zone, interest                  |
|Topic 30 |bill, amnesti, law, senat, amend, hous, govern, parliament, draft, legisl, propos, will, pass, thai, debat                    |
|Topic 31 |food, restaur, drink, coffe, tea, can, shop, fresh, fruit, dish, serv, thai, also, open, tast                                 |
|Topic 32 |market, product, said, sale, brand, year, compani, thailand, consum, new, thai, will, launch, also, local                     |
|Topic 33 |elect, reform, constitut, polit, vote, parti, charter, member, new, nation, draft, peopl, power, candid, propos               |
|Topic 34 |billion, year, million, said, last, first, worth, total, month, revenu, target, new, will, plan, next                         |
|Topic 35 |design, use, fashion, can, collect, also, new, colour, bag, brand, look, camera, light, black, featur                         |
|Topic 36 |develop, work, sustain, technolog, communiti, innov, programm, organis, help, research, support, thailand, also, creat, world |
|Topic 37 |said, nation, yesterday, peopl, thailand, countri, also, want, problem, help, need, believ, told, presid, meanwhil            |
|Topic 38 |prayut, minist, militari, prime, general, junta, ncpo, coup, chanocha, order, nation, govern, peac, thailand, countri         |
|Topic 39 |park, villag, anim, eleph, peopl, live, forest, area, local, nation, communiti, land, water, tree, year                       |
|Topic 40 |project, construct, will, infrastructur, develop, invest, plan, transport, govern, thailand, railway, road, rail, line, train |
|Topic 41 |tax, fund, pay, money, incom, million, cost, peopl, financi, will, fee, age, scheme, save, thailand                           |
|Topic 42 |event, thailand, presid, bangkok, award, organis, recent, intern, thai, held, left, campaign, centr, execut, group            |
|Topic 43 |bank, market, stock, loan, rate, thai, investor, bond, set, fund, index, billion, per, capit, foreign                         |
|Topic 44 |cambodia, sea, disput, cambodian, thailand, territori, court, templ, thai, area, border, minist, maritim, rule, foreign       |
|Topic 45 |compani, busi, invest, per, cent, group, firm, profit, oper, share, insur, list, execut, manag, revenu                        |
|Topic 46 |govern, countri, corrupt, polici, public, need, reform, thailand, nation, system, sector, problem, must, transpar, develop    |
|Topic 47 |rate, star, young, girl, famili, direct, woman, mother, thai, also, man, father, english, daughter, boy                       |
|Topic 48 |energi, power, plant, electr, oil, gas, ptt, use, product, generat, natur, produc, suppli, thailand, fuel                     |
|Topic 49 |educ, student, school, univers, children, teacher, learn, studi, thai, teach, languag, institut, also, english, graduat       |
|Topic 50 |thailand, one, can, peopl, thai, will, like, letter, mani, just, must, even, right, make, countri                             |
|Topic 51 |protest, polit, yingluck, govern, thaksin, shinawatra, democrat, minist, thai, parti, prime, peopl, leader, ralli, support    |
|Topic 52 |tourism, tourist, travel, thailand, thai, airport, airlin, flight, visitor, year, destin, intern, oper, foreign, number       |
|Topic 53 |properti, develop, project, land, bangkok, build, area, condominium, market, unit, hous, locat, squar, new, residenti         |
|Topic 54 |art, king, cultur, thai, artist, royal, exhibit, nation, templ, tradit, paint, museum, monk, majesti, show                    |
|Topic 55 |can, time, may, chang, need, one, howev, even, new, must, mani, still, make, like, now                                        |
|Topic 56 |germani, australia, franc, usa, australian, german, yesterday, new, itali, result, group, french, leagu, open, zealand        |
|Topic 57 |worker, labour, thailand, work, migrant, traffick, illeg, human, report, thai, employ, govern, wage, problem, job             |
|Topic 58 |depart, thailand, agenc, ministri, foreign, regul, thai, inform, standard, issu, intern, oper, offici, requir, law            |
|Topic 59 |car, vehicl, model, drive, driver, auto, motor, engin, new, also, toyota, road, honda, offer, bike                            |
|Topic 60 |gold, women, thailand, game, world, win, thai, men, team, final, medal, second, first, point, match                           |

<p align="center">Table 2: Fifteen most probable words for the topics</p>

```R
### LDAvis https://github.com/cpsievert/LDAvis & https://www.r-bloggers.com/a-link-between-topicmodels-lda-and-ldavis/
topicmodels_json_ldavis <- function(fitted, corpus, doc_term){
  ## Required packages
  library(topicmodels)
  library(dplyr)
  library(stringi)
  library(tm)
  library(LDAvis)
  
  ## Find required quantities
  phi <- posterior(fitted)$terms %>% as.matrix
  theta <- posterior(fitted)$topics %>% as.matrix
  vocab <- colnames(phi)
  doc_length <- vector()
  for (i in 1:length(corpus)) {
    temp <- paste(corpus[[i]]$content, collapse = ' ')
    doc_length <- c(doc_length, stri_count(temp, regex = '\\S+'))
  }
  temp_frequency <- as.matrix(doc_term[1:nrow(doc_term), 1:ncol(doc_term)])
  freq_matrix <- data.frame(ST = colnames(temp_frequency),
                            Freq = colSums(temp_frequency))
  rm(temp_frequency)
  
  ## Convert to json
  json_lda <- LDAvis::createJSON(phi = phi, theta = theta,
                                 vocab = vocab,
                                 doc.length = doc_length,
                                 term.frequency = freq_matrix$Freq)
  
  return(json_lda)
}


nation.jason <- topicmodels_json_ldavis(mod.out.60, nation, nation.dtm)
serVis(nation.jason, out.dir = "~/polisci490/Project")
```

<p align="center">
  <img src="https://naponjatusripitak.github.io/polisci490/Project/ldavis.png">
</p>
<p align="center">
Figrue 2: LDA visualization. (https://naponjatusripitak.github.io/polisci490/Project/index.html)
</p>


## Topic Variation over Time
For the purpose of this study, it is important that we can observe the topic variation over time. To do so, I group the data by topic and month and plot the average probability of topics. Higher values indicate greater association of documents, and words in the documents, with a given topic. For visualization, I select 6 topics which provide insights into the relationship between regime transition and the media (See Figure 3).

```R
### Selected Topic Frequencies Over Time
dft.select <- dft %>% select(id, date, "2","24", "33", "38", "46", "51")

M <- gather(dft.select,topic,value,-id,-date) %>%
  group_by(topic,month = floor_date(date, "month")) %>%
  summarize(value=mean(value))

ggplot(M,aes(x=month,y=value, col=factor(topic, labels=c("Agriculture", "Law", "Political Reform", "Junta", "Government", "Political Conflict")))) + 
  geom_point() +
  geom_line() +
  scale_x_date(date_breaks= "1 month", date_labels = "%B-%Y") +
  theme(axis.text.x=element_text(angle=45, hjust=1)) + 
  geom_vline(xintercept = as.numeric(as.Date("2014-05-22")), linetype=4) +
  #ggtitle("Topic Prevalence") +
  labs(color = "Topic")
```

<p align="center">
  <img src="https://naponjatusripitak.github.io/polisci490/Project/prevalence.png">
</p>
<p align="center">
Figrue 3: The dotted vertical line represents the May 2014 coup which removed the Pheu Thai government and installed a military government under the authority of the National Council for Peace and Order (NCPO)
</p>

Overall, the _Political Conflict_ topic undergoes the most dramatic shift, peaking in the months leading up to the the coup in May 2014. This represents the height of the conflict during the anti-government and anti-election protest by the People's Democratic Reform Committee (PDRC) which effectively shutdown Bangkok in an attempt to oust the Yingluck government and to boycott the election in February. The salience of this topic declines substantially after the military intervened and established a junta government. In contrast, the _Junta_ topic surges after the coup, signaling the media's attention to the NCPO and the military's involvement in politics.

Other notable shifts during this transition of power include: (1) a gradual increase in _Political Reform_ which reflects reform-related activities associated with the National Reform Council, National Legislative Assembly and Constitution Drafting Committee, all of which were appointed by the NCPO after the coup; (2) an overall decrease in the topic of _Agriculture_, reflecting reduced coverage on the rice-pledging scheme of the Yingluck government; (3) a rise in the topic of _Law_, denoting heightened coverage of anti-corruption and corruption related activities; (4) an increase in _Government_ which denotes greater coverage of government-related activites. It is plausible that some of these shifts may be attributable to the regime transition. However, without a reliable control group for comparison, it is difficult to make a causal statement regarding the relationship between the regime change and the topic variation observed. See below for a closer look at the frequencies of words over time in documents classified by the model as being highly associated with _Political Conflict_ (Figure 4) and _Junta_ (Figure 5).

```R
### Attach most associated topic to each document
nation.topics.df <- as.data.frame(nation.topics)
nation.topics.df <- transmute(nation.topics.df, doc_id = rownames(nation.topics.df), topic = nation.topics)
nation.topics.df$doc_id <- as.integer(nation.topics.df$doc_id)
df.out <- inner_join(df.2013, nation.topics.df, by = "doc_id")

### Tidy
tidy_df <- df.out %>%
  group_by(topic) %>%
  ungroup() %>%
  unnest_tokens(word, text)

### Word frequencies for selected topics
tidy_df %>% filter(topic == "51") %>% 
  group_by(date) %>%
  summarize(value=n()) %>%
  ggplot(aes(x=date,y=value)) + 
  geom_bar(stat = "identity", fill="skyblue") +
  scale_x_date(date_breaks= "3 month", date_labels = "%B %d, %Y") +
  theme(axis.text.x=element_text(angle=45, hjust=1)) + 
  geom_vline(xintercept = as.numeric(as.Date("2014-05-22")), linetype=4) +
  ggtitle("The Number of Words Written on the ‘Political Conflict’ Topic Per Day")

tidy_df %>% filter(topic == "38") %>% 
  group_by(date) %>%
  summarize(value=n()) %>%
  ggplot(aes(x=date,y=value)) + 
  geom_bar(stat = "identity", fill="skyblue") +
  scale_x_date(date_breaks= "3 month", date_labels = "%B %d, %Y") +
  theme(axis.text.x=element_text(angle=45, hjust=1)) + 
  geom_vline(xintercept = as.numeric(as.Date("2014-05-22")), linetype=4) +
  ggtitle("The Number of Words Written on the ‘Junta’ Topic Per Day")
```

<p align="center">
  <img src="https://naponjatusripitak.github.io/polisci490/Project/politicalconflict.png">
</p>
<p align="center">
Figrue 4: The Number of Words Written on the "Political Conflict" Topic Per Day
</p>

<p align="center">
  <img src="https://naponjatusripitak.github.io/polisci490/Project/junta.png">
</p>
<p align="center">
Figrue 5: The Number of Words Written on the "Junta" Topic Per Day
</p> 

## Sentiment Analysis
In addition to the topic model, I also conduct sentiment analysis using the labels generated by LDA. Each article is labeled as belonging to the topic with which it exhibits the highest probability. Using the bing lexicon which classifies words as positive and negative, I create unigram sentiment scores for the selected topics. For corpus-wide sentiments, see Figure (6). I also plot the variation in sentiments over time (see Figure 7).

### Sentiment analysis for selected topics
```R
topic.sentiment1  <- tidy_df %>% filter(topic == c("2","24", "33", "38", "46", "51")) %>%
  inner_join(get_sentiments("bing")) %>%
  count(topic, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)

topic.sentiment1 %>%
  ggplot(aes(factor(topic, labels=c("Agriculture", "Law", "Political Reform", "Junta", "Government", "Political Conflict")), sentiment)) +
  geom_bar(stat="identity", fill="skyblue3") +
  ylim(-700, 700) +
  xlab("Topic") +
  ylab("Sentiments")
```
<p align="center">
  <img src="https://naponjatusripitak.github.io/polisci490/Project/sentiments.png">
</p>
<p align="center">
Figrue 6: Sentiment Scores for Selected Topics
</p> 

### Sentiment analysis for selected topics over time
```R
topic.sentiment  <- tidy_df %>% filter(topic == c("2","24", "33", "38", "46", "51")) %>%
  inner_join(get_sentiments("bing")) %>%
  count(topic, date, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)

ggplot(topic.sentiment, aes(date, sentiment, fill = topic)) +
  geom_col(show.legend = FALSE) + 
  facet_wrap(~factor(topic, labels=c("Agriculture", "Law", "Political Reform", "Junta", "Government", "Political Conflict")), ncol = 2, scales = "free_x") +
  ylab("Sentiments") +
  xlab("Date") +
  ggtitle("Sentiment Analysis")
```
<p align="center">
  <img src="https://naponjatusripitak.github.io/polisci490/Project/sentimenttime.png">
</p>
<p align="center">
Figrue 7: Sentiment Variation Over Time
</p> 

On average, sentiments for the six selected topics are more positive after the coup than prior to the coup. This is most clearly illustrated in the plot for _Agriculture_, _Political Conflict_, _Political Reform_, and _Junta_. On the other hand, sentiments on _Government_ are more ambiguous, whereas sentiments on _Law_ are consistently negative.

## Prayut vs Yingluck
In this part, I break the newspaper articles into sections of 30 words. Then, I conduct a sentiment analysis on sections that mention _Prayut_ and _Yingluck_. Overall, sentiments associated with Yingluck became more negative after the coup, whereas the result is more ambiguous for sentiments associated with Prayut.

```R
### Sentiment Analysis
# Break doc into sections
section_words <- tidy_df %>% 
  group_by(doc_id) %>%
  mutate(section = row_number() %/% 30) %>%
  filter(section > 0) %>%
  filter(!word %in% stop_words$word)

# Yingluck
yingluck_sections <- section_words %>%
  group_by(doc_id, section) %>%
  filter(word=="yingluck") %>%
  select(doc_id, section) %>%
  inner_join(section_words)

yingluck.sentiments  <- yingluck_sections %>%
  inner_join(get_sentiments("bing")) %>%
  count(date, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative) %>%
  group_by(week = floor_date(date, "week")) %>%
  summarize(value=mean(sentiment))

# Prayut
prayut_sections <- section_words %>%
  group_by(doc_id, section) %>%
  filter(word == "prayut"|word == "prayuth") %>%
  select(doc_id, section) %>%
  inner_join(section_words)

prayut.sentiments  <- prayut_sections %>%
  inner_join(get_sentiments("bing")) %>%
  count(date, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative) %>%
  group_by(week = floor_date(date, "week")) %>%
  summarize(value=mean(sentiment))

# Graph
yingluck.sentiments$label <- "Yingluck"
prayut.sentiments$label <- "Prayut"
yingluck.vs.prayut <- full_join(yingluck.sentiments, prayut.sentiments)

ggplot(yingluck.vs.prayut, aes(week, value, col=label)) +
  geom_line() +
  theme_classic() +
  scale_x_date(date_breaks= "3 month", date_labels = "%b %Y") +
  theme(axis.text.x=element_text(angle=45, hjust=1)) + 
  geom_vline(xintercept = as.numeric(as.Date("2014-05-22")), linetype=4) +
  geom_hline(yintercept = 0, size=0.1) +
  theme(legend.position = "bottom", legend.title=element_blank()) +
  xlab("Date") +
  ylab("Sentiment") +
  scale_color_manual(values=c("#9999CC", "#CC6666"))
```
<p align="center">
  <img src="https://naponjatusripitak.github.io/polisci490/Project/prayutvsyingluck.png">
</p>
<p align="center">
Figrue 8: Sentiment Scores for Prayut and Yingluck (Weekly Averages)
</p> 

```R
### Top Topics associated with Yingluck and Prayut
tidy(mod.out.60) %>%
  filter(term == "yingluck") %>%
  top_n(10, beta) %>%
  arrange(-beta) %>%
  ggplot(aes(x=reorder(topic, -beta), y=beta)) +
  geom_bar(stat="identity", fill="tomato2") +
  coord_flip()

tidy(mod.out.60) %>%
  filter(term == "prayut"|term == "prayuth") %>%
  top_n(20, beta) %>%
  arrange(-beta) %>%
  ggplot(aes(x=reorder(topic, -beta), y=beta)) +
  geom_bar(stat="identity", fill="darkgreen")

### Table
topic_list <- data.frame(t(nation.terms))
topic_list <- within(topic_list, x <- paste(X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, sep=", ")) %>% select(x)
colnames(topic_list) <- NULL
topic_list <- tibble::rownames_to_column(topic_list)
colnames(topic_list) <- c("Topic", "Keys")

yingluck.pattern <- tidy(mod.out.60) %>%
  filter(term == "yingluck") %>%
  top_n(5, beta) %>%
  arrange(-beta) %>%
  select(topic)

prayut.pattern <- tidy(mod.out.60) %>%
  filter(term == "prayut") %>%
  top_n(5, beta) %>%
  arrange(-beta) %>%
  select(topic)
```

|   |Topic    |Keys                                                                                 |
|--|--------|------------------------------------------------------------------------------------|
|51 |Topic 51 |protest, polit, yingluck, govern, thaksin, shinawatra, democrat, minist, thai, parti |
|2  |Topic 2  |rice, farmer, price, tonn, govern, scheme, agricultur, million, export, rubber       |
|18 |Topic 18 |peac, muslim, group, south, talk, thai, insurg, govern, islam, secur                 |
|38 |Topic 38 |prayut, minist, militari, prime, general, junta, ncpo, coup, chanocha, order         |
|20 |Topic 20 |ministri, said, govern, minist, plan, nation, state, committe, budget, will          |
<p align="center">Top 5 Topics Associated with Yingluck Shinawatra</p>

|   |Topic    |Keys                                                                             |
|--|--------|--------------------------------------------------------------------------------|
|38 |Topic 38 |prayut, minist, militari, prime, general, junta, ncpo, coup, chanocha, order     |
|50 |Topic 50 |thailand, one, can, peopl, thai, will, like, letter, mani, just                  |
|33 |Topic 33 |elect, reform, constitut, polit, vote, parti, charter, member, new, nation       |
|20 |Topic 20 |ministri, said, govern, minist, plan, nation, state, committe, budget, will      |
|46 |Topic 46 |govern, countri, corrupt, polici, public, need, reform, thailand, nation, system |
<p align="center">Top 5 Topics Associated with Prayut Chan-o-cha</p>

## Conclusion
To conclude, the study reveals striking differences between newspaper articles that were published prior to and after the military takeover in May 2014 with regards to both topic prevalence and content within the topics identified by the model. However, it must be emphasized that this finding is merely _descriptive, not causal_. Further work is required in order to falsify or substantiate a **causal interpretation** of the observed differences which, in theory, could be due to a range of other factors beyond regime transition. Future studies should aim to incorporate a control group that is suitable for comparison and for ruling out potential confounding variables. Furthermore, even when the findings are robust, the difficulty of interpreting the variation in topic prevalence and content remains. Thus, **theory development** with regards to the relationship between regime transition and the media is necessary to spell out the mechanisms through which changes in political institutions and rules of the game translate into changes in public opinions and sentiments as reflected by the media. In terms of the methodology, the topic model in this study makes **modeling assumptions** regarding _the exchangeability of words_ and _the static nature of topics over time_. Implementing a topic model that accounts for the importance of word ordering (Wallach 2006) and the dynamic nature of topics (Blei and Lafferty 2006) would contribute to a more realistic representation of the latent topics and their variation in response to the regime transition.
