---
layout: post
title: Change or Continuity?
subtitle: Topic Modeling of Thailand in Transition
gh-repo: naponjatusripitak/polisci490/Project
gh-badge: [star, fork, follow]
tags: [LDA, politics]
---

## Introduction
<p align="center">
<img src="https://naponjatusripitak.github.io/polisci490/Project/thenation.png">
</p>

Do newspaper articles that are published before and after the occurrence of a regime transition differ systematically in terms of their topic coverage and content? Utilizing an original dataset containing all political news published from 2013 to 2015 by _The Nation_, an English-language daily newspaper in Thailand, this project explores the relationship between regime transition and the media. Specifically, I analyze Thai newspaper articles that were published under democratic rule (pre-May 2014 coup) and those that were published under military rule (post-May 2014 coup), using latent Dirichlet allocation (LDA) to examine topic variation amidst a regime transition. Then, leveraging the topics generated by the model, I conduct a series of quantitative content analyses for assessing the frequencies of words and measuring the sentiments associated with a given topic over time.

## Data Collection and Pre-Processing
All newspaper articles published by The Nation from 2013 to 2015 were collected from the Nexis Uni database via Rselenium, which extracted relevant information such as the headline, content, and date. The search query used in this process of data collection is _thailand_. For the analysis, only articles that contain a set of keywords that are predictive of their political content were retained for the analysis. These keywords include: politic*, gov*, democ*, Yingluck, junta, Prayut, Pheu, and NCPO. One problem with this strategy is that the keyword selection process is potentially arbitrary, inadequate for minimizing false positives and lacking in terms of intercoder reliability. An alternative strategy would be to use a computer-assisted approach offered by King, Lam and Roberts (2017), relying on an unsupervised selection of documents in search set, _S_, into target set, _T_, based on a hand-coded reference set _R_. However, in this project, the dictionary-based approach is selected for computational efficiency. This process yields a total of 20,703 articles where the average length is 580 words.

### Data Collection
```R
# Set working directory
setwd("~/polisci490/Project")

# Load packages
packages <- c("xml2","rvest", "dplyr", "tm", "tidytext", "ggplot2", "SnowballC", "tidyverse", "lubridate", "stringr", "httr", "SnowballC", "wdman", "RSelenium", "tcltk", "XML", "topicmodels", "stringi", "LDAvis", "slam", "ldatuning", "kableExtra", "widyr", "igraph", "ggraph", "fmsb", "pander")

load.packages <- function(x) {
  if (!require(x, character.only = TRUE)) {
    install.packages(x, dependencies = TRUE)
    library(x, character.only = TRUE)
  }
}

lapply(packages, load.packages)

########## Data Collection (Don't Run this!!)########## 

# Run Selenium Server
rD <- rsDriver()
remDr <- remoteDriver(remoteServerAddr = "localhost" 
                      , port = 4567L
                      , browserName = "chrome"
)


# Log in
remDr$open()
remDr$navigate("https://advance-lexis-com.turing.library.northwestern.edu/api/permalink/920dc8d1-6625-47c3-bdd4-b1c073f28f78/?context=1516831")
username <- remDr$findElement(using = 'id', value = "IDToken1")
password <- remDr$findElement(using = 'id', value = "IDToken2")
username$sendKeysToElement(list("id"))
password$sendKeysToElement(list("pass", "\uE007"))

# click

continue <- remDr$findElement(using = "xpath", "//*[@id='33Lk']/div/div/div/section/div/menu/input[1]")
continue$clickElement()

# Initializing an empy dataframe
# df <- data.frame(title=NULL, text=NULL, date=NULL, length=NULL)

# Scraping

remDr$setTimeout(type = "page load", milliseconds = 100000)
remDr$setImplicitWaitTimeout(milliseconds = 100000)
for(i in 1:20000){
  tryCatch({
    title <- remDr$findElement(using = "id", "SS_DocumentTitle")
    date <- remDr$findElement(using = "xpath", "//*[@id='document']/section/header/p[3]")
    length <- remDr$findElement(using = "xpath", "//*[@id='document']/section/span/div[2]")
    body <- remDr$findElement(using = "xpath", "//*[@id='document']/section/span")
    
    preptext <- function(x){ data.frame(matrix(unlist(x), nrow=length(x), byrow=T))}
    
    title_txt <- preptext(title$getElementText())
    date_txt <- preptext(date$getElementText())
    length_txt <- preptext(length$getElementText())
    body_txt <- preptext(body$getElementText())
    
    docdf <- data.frame(title=title_txt, text=body_txt, date=date_txt, length=length_txt)
    df <- rbind(df, docdf)
    
    Sys.sleep(sample(1:4, 1))
    next_page <- remDr$findElement(using="xpath", "//*[@id='_gLdk']/div/form/div[1]/div/div[14]/nav/span/button[2]")
    next_page$highlightElement()
    next_page$clickElement()
    
  }, error=function(e){
    Sys.sleep(sample(1:10, 1))
    title <- remDr$findElement(using = "id", "SS_DocumentTitle")
    date <- remDr$findElement(using = "xpath", "//*[@id='document']/section/header/p[3]")
    length <- remDr$findElement(using = "xpath", "//*[@id='document']/section/span/div[2]")
    body <- remDr$findElement(using = "xpath", "//*[@id='document']/section/span")
    
    preptext <- function(x){ data.frame(matrix(unlist(x), nrow=length(x), byrow=T))}
    
    title_txt <- preptext(title$getElementText())
    date_txt <- preptext(date$getElementText())
    length_txt <- preptext(length$getElementText())
    body_txt <- preptext(body$getElementText())
    
    docdf <- data.frame(title=title_txt, text=body_txt, date=date_txt, length=length_txt)
    df <- rbind(df, docdf)
    
    Sys.sleep(sample(1:4, 1))
    next_page <- remDr$findElement(using="xpath", "//*[@id='_gLdk']/div/form/div[1]/div/div[14]/nav/span/button[2]")
    next_page$highlightElement()
    next_page$clickElement()
  })}
```

### Data Pre-processing
```R
# Assign variable names
names(df) <- c("title", "text", "date", "wordcount")

# Set date
df$date <- mdy(as.character(df$date))

# Clean content
df$text <- gsub("^.*Body\n|Classification.*$","", as.character(df$text))
df$text <- gsub( " *@.*?; *", "", as.character(df$text))
df$text <- gsub( "*â€", "", as.character(df$text))
df$text <- gsub( "*â€“", "", as.character(df$text))
df$title <- gsub( " *@.*?; *", "", as.character(df$title))
df$title <- gsub( "*â€", "", as.character(df$title))
df$title <- gsub( "*â€“", "", as.character(df$title))
df$title <- gsub( "*#124", "", as.character(df$title))
df$text <- gsub( "*#124", "", as.character(df$text))
df$text <- gsub("*Prayuth", "Prayut", as.character(df$text)) # Prayut & Prayuth
df$title <- gsub("*Prayuth", "Prayut", as.character(df$title)) # Prayut & Prayuth

# Get word count
df$wordcount <- as.numeric(gsub("Length: | words", "", df$wordcount))

# Filter for politics
keyword <- c("politic*", "gov*", "democ*", "Yingluck", "junta", "Prayut", "Pheu", "NCPO")
pattern <- grepl(paste(keyword, collapse = "|"), df$text)
df <- df[pattern, ]

# select date Jan 2013 - Sep 2015
df.2013 <- filter(df, date >= "2013-01-01" & date < "2016-01-01")

# Remove duplicate rows
df.2013 <- distinct(df.2013)

# Add doc_id
df.2013 <- df.2013 %>% mutate(doc_id = seq.int(nrow(df.2013)))

# Finalize dataset
df.2013 <- df.2013 %>% select(doc_id, text, everything())
```
<p align="center">
<img src="https://naponjatusripitak.github.io/polisci490/Project/datastructurenation.png">
</p>
<p align="center">Table 1: Data Structure</p>

Using the tm package, I converted the data to a corpus object, transformed words to lower cases and removed stop words, numbers, punctuations, followed by stemming and removing white spaces. Then, I parsed the corpus to a document-term matrix with articles as documents in the rows and terms in the columns. Finally, sparse terms that appear in less than 0.01 of all documents are removed. One consideration that must taken into account is that the topic models may be sensitive to these pre-processing choices (Denny and Sperling 2017). In theory, transforming to lower cases, removing numbers and removing punctuations should not significantly alter the findings of this project, whereas stemming and removing stop words may result in a loss of information or generate noise in the model. Although a comparison of findings with different preprocessing choices is not presented here, this can be implemented in future work to test the robustness of the topic models.  

```R
# Create corpus
nation <- VCorpus(DataframeSource(df.2013))

# Pre-process + generate document-term matrix
nation.dtm <- nation %>% 
  tm_map(content_transformer(tolower)) %>%
  tm_map(removeWords, stopwords("english")) %>%
  tm_map(removeNumbers) %>%
  tm_map(removePunctuation) %>%
  tm_map(stemDocument) %>%
  tm_map(stripWhitespace) %>%
  DocumentTermMatrix() %>%
  removeSparseTerms(sparse = 0.99)
```

## Choosing the Number of Topics
Following Blei, Ng and Jordan (2003), I employ latent Dirichlet allocation (LDA) as an unsupervised method for learning the topics associated with the newspaper articles. This allows for documents to be represented as mixtures of topics characterized by a probabilistic distribution of words, in contrast to other models that treat documents as discrete and limited to a single topic.

I also considered using structural topic modeling (STM) as an alternative. However, given the lack of available covariates on which to condition the topic model on, LDA is chosen for the study. One consequence of this is that the model is likely to be noisy given that informative metadata such as news category is not included as part of the modeling.
                                 
To find the optimal number of topics for fitting LDA models, I use _ldatuning_, an R package that estimates the performance of LDA models based on four different metrics. According to these metrics, the performance of LDA models improves most significantly when moving to 40 and 60 topics.

```R
result <- FindTopicsNumber(
  nation.dtm,
  topics = seq(from = 20, to = 200, by = 10),
  metrics = c("Griffiths2004", "CaoJuan2009", "Arun2010", "Deveaud2014"),
  method = "Gibbs",
  control = list(seed = 77),
  mc.cores = 2L,
  verbose = TRUE
)
FindTopicsNumber_plot(result)
```
<p align="center">
<img src="https://naponjatusripitak.github.io/polisci490/Project/ldatuning.png">
</p>
<p align="center">Figure 1: LDA Tuning</p>

## Topic Model (2013-2015)
 I implemented four topic models with k = 20, 30, 40 and 60. Out of all four models, the model with k = 60 is most informative in terms of providing topic labels that are helpful for making an informed guess as to what each topic is about. Each document is modeled as a mixture of topics and, under the bag-of-words assumption, a distribution of words with probabilities of being associated with various topics. Table 2 provides all sixty topics and the terms most frequently associated with them. Figure 2 illustrates an interactive web-based visualization of the model.

```R
### LDA
mod.out.60 <- LDA(nation.dtm, k=60, control = list(seed=6))
class(mod.out.60) <- "LDA"
tidy(mod.out.60)

### Generate topic labels (top 30 terms)
nation.topics <- topics(mod.out.60, 1)
nation.terms <- as.data.frame(terms(mod.out.60, 30), stringsAsFactors = FALSE)

### Table
topic_list <- data.frame(t(nation.terms))
topic_list <- within(topic_list, x <- paste(X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X12, X13, X14, X15, X16, X17, X18, X19, X20, sep=", ")) %>% select(x)
colnames(topic_list) <- NULL
topic_list <- tibble::rownames_to_column(topic_list)
colnames(topic_list) <- c("Topic", "Keys")
```
|Topic    |Keys                                                                                                                          |
|:--------|:-----------------------------------------------------------------------------------------------------------------------------|
|Topic 1  |health, hospit, medic, patient, treatment, doctor, diseas, drug, healthcar, peopl, also, medicin, cancer, can, servic         |
|Topic 2  |rice, farmer, price, tonn, govern, scheme, agricultur, million, export, rubber, said, farm, market, pledg, crop               |
|Topic 3  |channel, digit, broadcast, licenc, nbtc, servic, oper, auction, telecom, nation, advertis, station, content, telecommun, true |
|Topic 4  |myanmar, lao, countri, cambodia, border, yangon, vietnam, mekong, neighbour, foreign, open, local, group, develop, year       |
|Topic 5  |asean, region, econom, countri, cooper, aec, thailand, communiti, member, trade, also, develop, will, integr, agreement       |
|Topic 6  |provinc, chiang, water, mai, district, flood, local, river, dam, nakhon, buri, area, rai, mae, thani                          |
|Topic 7  |will, year, new, next, thailand, also, expect, countri, thai, futur, take, come, hope, can, first                             |
|Topic 8  |asia, region, southeast, asian, countri, world, global, vietnam, east, asiapacif, thailand, india, across, singapor, pacif    |
|Topic 9  |polit, thailand, countri, thai, state, militari, nation, democraci, govern, intern, year, right, power, conflict, peopl       |
|Topic 10 |media, social, facebook, post, news, onlin, peopl, thai, page, report, messag, websit, inform, also, video                    |
|Topic 11 |meet, said, will, yesterday, month, thailand, day, week, report, two, last, announc, offici, schedul, committe                |
|Topic 12 |per, cent, year, quarter, growth, increas, expect, month, price, last, averag, rate, first, forecast, drop                    |
|Topic 13 |malaysia, singapor, indonesia, fish, philippin, boat, malaysian, indonesian, sea, ship, vessel, said, jakarta, marin, countri |
|Topic 14 |trade, thai, thailand, export, industri, product, invest, countri, said, import, busi, manufactur, year, will, market         |
|Topic 15 |attack, secur, bomb, kill, incid, death, polic, peopl, fire, accid, violenc, bangkok, injur, also, victim                     |
|Topic 16 |busi, custom, servic, compani, thailand, provid, new, manag, market, oper, growth, store, retail, cloud, industri             |
|Topic 17 |mobil, use, technolog, internet, servic, devic, onlin, user, phone, data, card, can, app, applic, smart                       |
|Topic 18 |peac, muslim, group, south, talk, thai, insurg, govern, islam, secur, leader, region, offici, deep, local                     |
|Topic 19 |say, like, one, just, time, want, get, peopl, can, work, think, now, make, year, know                                         |
|Topic 20 |ministri, said, govern, minist, plan, nation, state, committe, budget, will, polici, financ, propos, offic, privat            |
|Topic 21 |economi, econom, growth, rate, thailand, invest, year, polici, domest, global, export, govern, bank, polit, market            |
|Topic 22 |polic, said, arrest, suspect, rohingya, yesterday, investig, thailand, report, two, nation, thai, alleg, found, offici        |
|Topic 23 |china, chines, south, hong, korea, kong, india, beij, korean, taiwan, japan, indian, thailand, mainland, includ               |
|Topic 24 |court, right, case, law, legal, nation, rule, public, also, issu, violat, human, alleg, justic, report                        |
|Topic 25 |team, player, thai, footbal, club, game, match, cup, play, nation, coach, fan, leagu, world, thailand                         |
|Topic 26 |film, music, perform, festiv, show, thai, danc, movi, theatr, year, stage, also, audienc, play, song                          |
|Topic 27 |hotel, offer, call, wine, bangkok, room, resort, night, includ, beach, two, book, spa, restaur, ticket                        |
|Topic 28 |tour, said, play, win, golf, round, last, shot, hole, year, open, two, birdi, week, first                                     |
|Topic 29 |japan, japanes, tokyo, thailand, thai, yen, visit, also, oversea, bangkok, open, first, year, zone, interest                  |
|Topic 30 |bill, amnesti, law, senat, amend, hous, govern, parliament, draft, legisl, propos, will, pass, thai, debat                    |
|Topic 31 |food, restaur, drink, coffe, tea, can, shop, fresh, fruit, dish, serv, thai, also, open, tast                                 |
|Topic 32 |market, product, said, sale, brand, year, compani, thailand, consum, new, thai, will, launch, also, local                     |
|Topic 33 |elect, reform, constitut, polit, vote, parti, charter, member, new, nation, draft, peopl, power, candid, propos               |
|Topic 34 |billion, year, million, said, last, first, worth, total, month, revenu, target, new, will, plan, next                         |
|Topic 35 |design, use, fashion, can, collect, also, new, colour, bag, brand, look, camera, light, black, featur                         |
|Topic 36 |develop, work, sustain, technolog, communiti, innov, programm, organis, help, research, support, thailand, also, creat, world |
|Topic 37 |said, nation, yesterday, peopl, thailand, countri, also, want, problem, help, need, believ, told, presid, meanwhil            |
|Topic 38 |prayut, minist, militari, prime, general, junta, ncpo, coup, chanocha, order, nation, govern, peac, thailand, countri         |
|Topic 39 |park, villag, anim, eleph, peopl, live, forest, area, local, nation, communiti, land, water, tree, year                       |
|Topic 40 |project, construct, will, infrastructur, develop, invest, plan, transport, govern, thailand, railway, road, rail, line, train |
|Topic 41 |tax, fund, pay, money, incom, million, cost, peopl, financi, will, fee, age, scheme, save, thailand                           |
|Topic 42 |event, thailand, presid, bangkok, award, organis, recent, intern, thai, held, left, campaign, centr, execut, group            |
|Topic 43 |bank, market, stock, loan, rate, thai, investor, bond, set, fund, index, billion, per, capit, foreign                         |
|Topic 44 |cambodia, sea, disput, cambodian, thailand, territori, court, templ, thai, area, border, minist, maritim, rule, foreign       |
|Topic 45 |compani, busi, invest, per, cent, group, firm, profit, oper, share, insur, list, execut, manag, revenu                        |
|Topic 46 |govern, countri, corrupt, polici, public, need, reform, thailand, nation, system, sector, problem, must, transpar, develop    |
|Topic 47 |rate, star, young, girl, famili, direct, woman, mother, thai, also, man, father, english, daughter, boy                       |
|Topic 48 |energi, power, plant, electr, oil, gas, ptt, use, product, generat, natur, produc, suppli, thailand, fuel                     |
|Topic 49 |educ, student, school, univers, children, teacher, learn, studi, thai, teach, languag, institut, also, english, graduat       |
|Topic 50 |thailand, one, can, peopl, thai, will, like, letter, mani, just, must, even, right, make, countri                             |
|Topic 51 |protest, polit, yingluck, govern, thaksin, shinawatra, democrat, minist, thai, parti, prime, peopl, leader, ralli, support    |
|Topic 52 |tourism, tourist, travel, thailand, thai, airport, airlin, flight, visitor, year, destin, intern, oper, foreign, number       |
|Topic 53 |properti, develop, project, land, bangkok, build, area, condominium, market, unit, hous, locat, squar, new, residenti         |
|Topic 54 |art, king, cultur, thai, artist, royal, exhibit, nation, templ, tradit, paint, museum, monk, majesti, show                    |
|Topic 55 |can, time, may, chang, need, one, howev, even, new, must, mani, still, make, like, now                                        |
|Topic 56 |germani, australia, franc, usa, australian, german, yesterday, new, itali, result, group, french, leagu, open, zealand        |
|Topic 57 |worker, labour, thailand, work, migrant, traffick, illeg, human, report, thai, employ, govern, wage, problem, job             |
|Topic 58 |depart, thailand, agenc, ministri, foreign, regul, thai, inform, standard, issu, intern, oper, offici, requir, law            |
|Topic 59 |car, vehicl, model, drive, driver, auto, motor, engin, new, also, toyota, road, honda, offer, bike                            |
|Topic 60 |gold, women, thailand, game, world, win, thai, men, team, final, medal, second, first, point, match                           |

<p align="center">Table 2: Fifteen most probable words for the topics</p>

## Topic Variation over Time
For the purpose of this study, it is important that we can observe the topic variation over time. To do so, I group the data by topic and month and plot the average probability of topics. Higher values indicate greater association of documents, and words in the documents, with a given topic. For visualization, I select 6 topics which provide insights into the relationship between regime transition and the media (See Figure 3).

<p align="center">
  <img src="ldavis.png">
</p>
<p align="center">
LDA visualization. URL: [https://naponjatusripitak.github.io/polisci490/Project/index.html](https://naponjatusripitak.github.io/polisci490/Project/index.html)
</p>


 
